# ---------------------------------------------------------------------------
# //
#
# Air Force Research Laboratory (AFRL) Autonomous Capabilities Team (ACT3)
# Reinforcement Learning (RL) Core contributed by the:
#  -  () Team
#  - Safe Autonomy (SA) Team
#
# This is a US Government Work not subject to copyright protection in the US.
#
# The use, dissemination or disclosure of data in this file is subject to
# limitation or restriction. See accompanying README and LICENSE for details.
# ---------------------------------------------------------------------------

####################################################################
# Override values used by the setup
####################################################################
experiment_class: scripts.test_cwh_rta_final.RllibExperiment
config:
  rllib_config_updates: &rllib_config_updates
    #num_workers: 0

  # No overrides for ray as there are no changes
  ray_config_updates: &ray_config_updates
    local_mode: True

  # Change the default path for saving out the data
  env_config_updates: &env_config_updates
    TrialName: Learjet-Rejoin-HSA-frame-stacking
    output_path: /tmp//act3

  # Change the default path for saving out the data
  tune_config_updates: &tune_config_updates
    local_dir: /tmp//ray_results/

  ####################################################################
  # Setup the actual keys used by the code
  # Note that items are patched from the update section
  ###################################################################
  rllib_configs:
    default: [!include rllib_config.yml, *rllib_config_updates]
    local: [!include rllib_config.yml,  *rllib_config_updates]

  ray_config: [!include ray_config.yml, *ray_config_updates]
  env_config: [!include ../../environments/cwh3d.yml, *env_config_updates]
  tune_config: [!include tune_config.yml, *tune_config_updates]
