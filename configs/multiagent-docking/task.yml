#--------------------------------------------------------------------------
#Air Force Research Laboratory (AFRL) Autonomous Capabilities Team (ACT3)
#Reinforcement Learning (RL) Core Extension.
#
#This is a US Government Work not subject to copyright protection in the US.
#
#The use, dissemination or disclosure of data in this file is subject to
#limitation or restriction. See accompanying README and LICENSE for details.
#---------------------------------------------------------------------------

####################################################################
# Task-specific configuration overrides
####################################################################

auto_system_detect_class: corl.experiments.base_experiment.BaseAutoDetect
experiment_class: corl.experiments.rllib_experiment.RllibExperiment

config:
  rllib_config_updates: &rllib_config_updates
    horizon: 5000
    num_workers: 6

  # No overrides for ray as there are no changes
  ray_config_updates: &ray_config_updates
    local_mode: false

  # Change the default path for saving out the data
  env_config_updates: &env_config_updates
    TrialName: MULTIAGENT-DOCKING
    output_path: ./output/env/

  # Change the default path for saving out the data
  tune_config_updates: &tune_config_updates

  ####################################################################
  # Setup the actual keys used by the code
  # Note that items are patched from the update section
  ###################################################################
  rllib_configs:
    default: [!include configs/multiagent-docking/rllib.yml, *rllib_config_updates]
    local: [!include configs/multiagent-docking/rllib.yml,  *rllib_config_updates]

  ray_config: [!include configs/multiagent-docking/ray.yml, *ray_config_updates]
  env_config: [!include configs/multiagent-docking/environment.yml, *env_config_updates]
  tune_config: [!include configs/multiagent-docking/tune.yml, *tune_config_updates]
